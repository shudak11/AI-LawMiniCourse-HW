# AI & Law Mini-Course HW Session 1
 
Sara Hudak and John Chapman

(1) Supreme Court case assignment

Step 1: collecting and preparing preliminary case data 

The first step involves collecting Supreme Court cases from FindLaw’s searchable Supreme Court database. The code defines the years of interest (i.e., the range of years from which published cases are to be collected). The code collects the data in a hierarchical structure, e.g., an array, and tags each item of information with a variable so that this information can be displayed to a user as desired (e.g., case title, case url, docket number, year; these items of information are linked so that the information from a single Supreme Court case are associated as one case input with multiple variables). The information is “Pickled” and attributes, such as the number of cases collected, can be returned to the user.

Step 2: collecting case opinion text 

The second step involves completing the array built in Step 1 by adding in the full text of the opinion of each case. The case text is collected by “scraping.” Temporary data frames (dfs) are established so that a case law source doesn’t detect too many requests from our scraper and subsequently block our IP address effectively halting our collection of the case text. Step 2 is completed by saving the fully compiled table, which at this point will be a sizable file.

Step 3: text processing

The third step involves processing the text of each opinion from the cases to prepare the text for subsequent analysis. The two major components of this step are: (i) removing stopwords (i.e., words that we are not interested in when analyzing the text); and (ii) lemmatizing the text (i.e., simplifying types of words to their root, e.g., modifying liking to like). Stopwords removed in this step include: state names, case names, common and not useful words (such as “the”), people names, day of the week, month names, and non-words (such as case reference numbers). The resulting modified texts of the cases will produce more meaningful modeling and topic analysis.

Step 4: model fitting

The fourth step involves using 3 modeling approaches to independently analyze the text processed in Step 3. As a reminder, the goal of the project is to be able to assess the topic of each case without having to read the case using modeling techniques that take into account word associations. Each modeling technique may need adjustment to more accurately gauge the case topic. The first modeling technique is latent dirichlet allocation (LDA). Modeling via LDA can be adjusted using frequency filters, part of speech tag filters, and use of batchwise LDA. The second modeling technique is non-negative matrices factorization (NMF). The third modeling technique is truncated SVD  (LSA), however, it is noted that this modeling technique may return that the each case is about law and not the topic of law.


Step 5: assigning a case topic and visualizing the data

The fifth step first involves creating topics each having an associated word dictionary and using the modeling from Step 4 (specifically NMF) and the topic dictionaries to assign each case with a topic. Each word in a topic dictionary is used as a “look up” using the modeling information. Running this code will then assign each case to a designated topic based on the associated topic dictionary. The initial array started in Step 1 can then be updated with the acquired information and associate call variables, such as assigned topic and topic dictionary words. This information can then be printed as a table or used for further manipulation, e.g., tabulating or plotting case per topic per year.


(2) Tensorflow Word2vec assignment

Step 1: downloading the data

The first step involves initially loading the first batch of code into a Jupyter notebook and subsequently executing the code via shift+enter. (Note: we were unable to link the cloned repository with the docker bin as the numerous instructions for this step did not work. The tutorial was completed using a separate notebook and a copy of the output is provided after the summary of the steps.) The file was created for the data and the data was read into strings as a list of individual words. 

Step 2: building the dictionary and replacing rare words with UNK token.

The second step involves building the dictionary from raw data of words. Using the words, a dictionary was built (words were assigned codes) and rare words were replaced with UNK tokens. 4 global variable were assessed, including the data, word count, the dictionary, and the reverse dictionary (and some of these items were printed, e.g., 5 most common words and a 10 sample dictionary).

Step 3: generating a training batch for the skip-gram model.

The third step involves using the information generated in Step 2 to create a training batch for skip-gram modeling. Variables such as “batch_size,” “num_skips,” and “skip_window” were used to create the training batch.

Step 4: building and training a skip-gram model.

The fourth step involves building and training a skip-gram model using the information generated in Steps 2 and 3. The skip-gram model was built using set constraints on the “batch_size,” “embedding_size,” “skip_window,” “num_skips,” and “num_sampled.” Next a random validation set was constructed to sample nearest neighbors. Following this, variables were constructed to assess NCE loss and the SGD optimizer was constructed using a learning rate of 1.0.

Step 5: further training the skip-gram model

The fifth step involves initiating the training of the skip-gram model. Variable were initiated before use and one update step was performed by evaluating the optimizer op. The average loss is an estimate of the loss over the last 2000 batches.

Step 6: visualizing the embeddings.

The sixth step involves graphically visualizing the information obtained from Step 5. This step includes a function to draw visualization of distance between embeddings so that the data may be graphically visualized.

Tutorial output:

Found and verified text8.zip Data size 17005207 Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)] Sample data [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] 3081 originated -> 5234 anarchism 3081 originated -> 12 as 12 as -> 3081 originated 12 as -> 6 a 6 a -> 12 as 6 a -> 195 term 195 term -> 6 a 195 term -> 2 of Initialized Average loss at step  0 :  274.035003662 Nearest to can: moreover, debra, adolph, erickson, jomo, bavaria, gini, johnson, Nearest to at: cigars, patass, bohdan, best, masculism, dualism, oct, depends, Nearest to in: sealing, villains, neurobiology, yasser, enlai, mushroom, tears, patagonian, Nearest to its: sanitation, stranded, luminiferous, trades, typewriter, beryl, bindings, consolidated, Nearest to into: inhumane, remade, stumbling, anode, renouf, busan, sensors, polynomials, Nearest to zero: apostle, heats, some, deliberations, brighton, cleaner, hydrogenation, hbo, Nearest to war: starfighter, sextus, unelected, biases, purchasing, vig, studded, guis, Nearest to often: prejudiced, histology, resumption, normale, morgenstern, libration, artistry, philologists, Nearest to so: wider, adopted, iit, rouen, floorball, vertebrates, grenada, soundtracks, Nearest to the: legation, fenway, riddler, cream, release, graz, agrippina, gillette, Nearest to after: clarity, prescribed, midwives, nau, euphemisms, jamahiriya, tradition, persuade, Nearest to were: fated, winding, monody, upholding, sequencing, newsreel, boo, stubbs, Nearest to over: rameses, brassiere, consulted, hiker, stargate, directional, frustrating, ventricles, Nearest to than: israeli, literal, nilo, chloe, integrins, subiaco, myoglobin, parsing, Nearest to to: interspersed, bandage, microgravity, watery, microstate, hellenism, excited, rimini, Nearest to had: nightly, admiral, tech, doubts, superlative, chopped, exporting, conservatoire, Average loss at step  2000 :  113.985288004 Average loss at step  4000 :  52.4965241439 Average loss at step  6000 :  33.2241598406 Average loss at step  8000 :  23.4610301661 Average loss at step  10000 :  17.8914954028 Nearest to can: moreover, analogue, severely, publishers, UNK, nhk, ngc, killed, Nearest to at: and, in, best, sigma, dualism, precisely, fao, application, Nearest to in: and, of, on, from, by, nine, for, to, Nearest to its: the, association, polar, brand, mises, aquarius, mosque, his, Nearest to into: anode, richard, prophecies, formation, references, compares, balancing, ethical, Nearest to zero: nine, one, coke, eight, bckgr, six, four, gland, Nearest to war: objection, emergency, austria, influencing, least, gases, activity, champion, Nearest to often: it, histology, commercial, institutions, economic, wilmot, omega, water, Nearest to so: wider, adopted, meade, snaps, neutral, accept, think, tower, Nearest to the: a, and, UNK, mctaggart, this, his, one, archie, Nearest to after: gland, crisis, sized, prescribed, process, python, bill, triangle, Nearest to were: are, winding, chaos, he, infected, and, socialists, h, Nearest to over: cracking, royal, spassky, many, bus, consulted, one, way, Nearest to than: israeli, literal, nilo, on, as, cap, single, reinforcements, Nearest to to: and, in, for, officers, excited, of, archie, notions, Nearest to had: exporting, have, rear, admiral, followed, was, as, adolescence, Average loss at step  12000 :  13.9388194976 Average loss at step  14000 :  11.9037048875 Average loss at step  16000 :  10.000262145 Average loss at step  18000 :  8.48240660691 Average loss at step  20000 :  8.03037133956 Nearest to can: moreover, to, is, severely, may, could, mlb, and, Nearest to at: in, and, agouti, on, for, from, meals, solicitor, Nearest to in: and, at, from, of, on, for, by, nine, Nearest to its: the, his, their, her, polar, aquarius, mises, these, Nearest to into: agouti, by, compares, apatosaurus, richard, state, prophecies, summary, Nearest to zero: nine, eight, seven, four, dasyprocta, six, five, operatorname, Nearest to war: operatorname, objection, influencing, sextus, anchors, emergency, leaky, soundly, Nearest to often: it, there, histology, slovakian, institutions, he, however, elephant, Nearest to so: adopted, wider, snaps, neutral, tower, accept, hits, meade, Nearest to the: a, his, operatorname, its, dasyprocta, one, this, and, Nearest to after: gland, sized, prescribed, crisis, and, acacia, fond, in, Nearest to were: are, was, and, is, he, winding, adiabatic, being, Nearest to over: many, cracking, consulted, unconstitutional, from, spassky, stargate, and, Nearest to than: israeli, literal, nilo, agouti, on, cap, reinforcements, six, Nearest to to: and, for, from, officers, nine, in, agouti, would, Nearest to had: have, was, has, exporting, admiral, rear, forbidding, followed, Average loss at step  22000 :  7.02307189393 Average loss at step  24000 :  6.84795750773 Average loss at step  26000 :  6.82896585488 Average loss at step  28000 :  6.41106118178 Average loss at step  30000 :  5.88262335277 Nearest to can: may, to, could, must, will, moreover, would, severely, Nearest to at: in, and, birkenau, on, agouti, from, by, for, Nearest to in: at, and, from, on, by, for, of, with, Nearest to its: the, their, his, her, this, hbox, them, aquarius, Nearest to into: by, speedup, in, birkenau, under, mutated, to, agouti, Nearest to zero: six, five, seven, eight, four, nine, three, dasyprocta, Nearest to war: emigrant, influencing, objection, leaky, celsius, operatorname, soundly, sextus, Nearest to often: it, there, also, that, histology, however, slovakian, ceramic, Nearest to so: adopted, wider, snaps, abet, neutral, tower, accept, por, Nearest to the: its, this, a, his, abet, operatorname, their, dasyprocta, Nearest to after: gland, sized, crisis, acacia, prescribed, in, fond, python, Nearest to were: are, was, is, by, had, being, adiabatic, winding, Nearest to over: from, and, many, consulted, bus, unconstitutional, in, cracking, Nearest to than: israeli, aegina, literal, or, nilo, and, agouti, firmness, Nearest to to: for, would, agouti, nine, and, can, in, from, Nearest to had: has, have, was, exporting, were, is, rear, by, Average loss at step  32000 :  5.95004975128 Average loss at step  34000 :  5.68763033533 Average loss at step  36000 :  5.79915965128 Average loss at step  38000 :  5.50824558973 Average loss at step  40000 :  5.27706174278 Nearest to can: may, will, could, must, would, to, moreover, should, Nearest to at: in, on, birkenau, agouti, from, and, by, zero, Nearest to in: at, and, from, on, zero, of, agouti, with, Nearest to its: their, the, his, her, hbox, them, this, aquarius, Nearest to into: by, from, speedup, under, birkenau, in, cajun, mutated, Nearest to zero: eight, six, seven, five, four, nine, three, dasyprocta, Nearest to war: emigrant, influencing, leaky, objection, celsius, soundly, operatorname, spent, Nearest to often: there, it, also, histology, that, rumoured, ceramic, never, Nearest to so: adopted, wider, snaps, abet, tower, neutral, hne, accept, Nearest to the: its, abet, his, their, a, this, operatorname, dasyprocta, Nearest to after: gland, sized, in, acacia, crisis, prescribed, was, process, Nearest to were: are, was, is, had, by, have, be, being, Nearest to over: from, consulted, many, birkenau, spassky, unconstitutional, zero, provision, Nearest to than: aegina, or, israeli, firmness, literal, nilo, agouti, six, Nearest to to: nine, for, would, agouti, zero, vma, not, from, Nearest to had: has, have, was, were, exporting, vma, are, admiral, Average loss at step  42000 :  5.36838694382 Average loss at step  44000 :  5.22615540886 Average loss at step  46000 :  5.26624958098 Average loss at step  48000 :  5.21653857207 Average loss at step  50000 :  5.00798133838 Nearest to can: may, could, will, must, would, to, should, portraits, Nearest to at: in, on, birkenau, agouti, from, three, four, and, Nearest to in: at, from, on, and, of, with, for, three, Nearest to its: their, the, his, her, hbox, them, aquarius, this, Nearest to into: from, under, speedup, by, birkenau, in, cajun, polynomials, Nearest to zero: eight, six, seven, five, four, nine, three, operatorname, Nearest to war: emigrant, influencing, leaky, objection, soundly, celsius, operatorname, sextus, Nearest to often: there, also, it, histology, still, usually, rumoured, which, Nearest to so: snaps, adopted, wider, abet, tower, neutral, hne, vittoria, Nearest to the: its, their, his, abet, this, a, operatorname, dasyprocta, Nearest to after: gland, four, sized, in, seven, six, acacia, eight, Nearest to were: are, was, had, is, have, be, being, by, Nearest to over: from, kapoor, roshan, consulted, in, bus, birkenau, three, Nearest to than: or, aegina, firmness, agouti, literal, undefined, circ, israeli, Nearest to to: nine, for, agouti, and, from, would, can, recitative, Nearest to had: has, have, was, were, exporting, is, vma, by, 
Average loss at step  52000 :  5.04649673128 Average loss at step  54000 :  5.18553851676 Average loss at step  56000 :  5.05625542653 Average loss at step  58000 :  5.05632308459 Average loss at step  60000 :  4.93951418376 Nearest to can: may, could, will, must, would, should, to, agouti, Nearest to at: in, birkenau, agouti, on, from, five, three, and, Nearest to in: from, on, at, and, ursus, of, during, agouti, Nearest to its: their, his, the, her, hbox, aquarius, them, pettigrew, Nearest to into: from, under, speedup, birkenau, through, cajun, mutated, by, Nearest to zero: seven, eight, six, five, four, nine, three, dasyprocta, Nearest to war: influencing, emigrant, leaky, objection, soundly, studded, operatorname, celsius, Nearest to often: there, also, it, ursus, usually, still, histology, rumoured, Nearest to so: adopted, abet, snaps, neutral, wider, sometimes, hne, tower, Nearest to the: their, its, operatorname, abet, this, a, dasyprocta, birkenau, Nearest to after: gland, six, in, acacia, four, was, during, five, Nearest to were: are, was, had, have, being, be, been, is, Nearest to over: kapoor, from, microbats, consulted, in, roshan, birkenau, provision, Nearest to than: or, aegina, seven, firmness, undefined, agouti, circ, limbs, Nearest to to: ursus, would, can, nine, not, agouti, for, will, Nearest to had: has, have, was, were, kapoor, dasyprocta, vma, exporting, Average loss at step  62000 :  5.01197711432 Average loss at step  64000 :  4.84626052409 Average loss at step  66000 :  4.59650729072 Average loss at step  68000 :  4.97472740066 Average loss at step  70000 :  4.90073004794 Nearest to can: may, could, will, would, must, should, to, agouti, Nearest to at: in, birkenau, cebus, on, agouti, vanishes, microcebus, during, Nearest to in: at, and, ursus, from, on, agouti, circ, under, Nearest to its: their, his, the, her, them, hbox, him, aquarius, Nearest to into: from, under, through, speedup, birkenau, cajun, mutated, by, Nearest to zero: eight, five, seven, six, four, nine, three, ursus, Nearest to war: influencing, emigrant, soundly, objection, leaky, studded, operatorname, premise, Nearest to often: there, also, usually, it, mitral, still, ursus, rumoured, Nearest to so: abet, neutral, snaps, adopted, sometimes, por, compromising, universally, Nearest to the: their, its, this, his, a, abet, operatorname, dasyprocta, Nearest to after: gland, in, during, was, upanija, four, acacia, davidian, Nearest to were: are, was, have, had, being, been, gaulish, be, Nearest to over: kapoor, from, microbats, consulted, four, dancers, birkenau, roshan, Nearest to than: nanotube, aegina, or, firmness, undefined, and, seven, limbs, Nearest to to: would, ursus, can, agouti, not, must, archie, will, Nearest to had: has, have, was, were, exporting, never, kapoor, dasyprocta, Average loss at step  72000 :  4.74493160629 Average loss at step  74000 :  4.79987034667 Average loss at step  76000 :  4.73553914058 Average loss at step  78000 :  4.79808768377 Average loss at step  80000 :  4.79742814499 Nearest to can: may, could, will, must, would, should, to, cannot, Nearest to at: in, birkenau, on, during, cebus, vanishes, five, microcebus, Nearest to in: from, at, and, ursus, during, agouti, nine, under, Nearest to its: their, his, the, her, them, hbox, pierrot, aquarius, Nearest to into: from, under, through, busan, speedup, in, birkenau, mutated, Nearest to zero: five, four, six, seven, eight, nine, operatorname, three, Nearest to war: influencing, emigrant, soundly, leaky, objection, studded, sextus, superscription, Nearest to often: usually, also, there, mitral, still, ursus, it, generally, Nearest to so: iit, abet, neutral, artifacts, sometimes, adopted, por, compromising, Nearest to the: their, its, a, his, operatorname, abet, dasyprocta, busan, Nearest to after: during, gland, davidian, iit, upanija, in, acacia, was, Nearest to were: are, was, have, had, being, be, been, gaulish, Nearest to over: kapoor, microbats, consulted, in, from, dancers, birkenau, theosis, Nearest to than: or, nanotube, aegina, firmness, undefined, circ, and, agouti, Nearest to to: ursus, would, agouti, callithrix, busan, recitative, for, must, Nearest to had: has, have, was, were, by, never, exporting, kapoor, Average loss at step  82000 :  4.77680921066 Average loss at step  84000 :  4.75351602244 Average loss at step  86000 :  4.77064936113 Average loss at step  88000 :  4.74921664357 Average loss at step  90000 :  4.72659571445 Nearest to can: may, could, will, would, must, should, to, might, Nearest to at: in, on, birkenau, cebus, during, microcebus, agouti, vanishes, Nearest to in: at, during, on, within, under, from, ursus, agouti, Nearest to its: their, his, the, her, aquarius, them, hbox, pettigrew, Nearest to into: from, through, under, busan, within, speedup, birkenau, to, Nearest to zero: five, eight, seven, six, four, nine, three, operatorname, Nearest to war: influencing, emigrant, leaky, soundly, objection, studded, calypso, sextus, Nearest to often: usually, also, there, still, generally, sometimes, it, mitral, Nearest to so: iit, abet, artifacts, neutral, por, compromising, however, tower, Nearest to the: their, its, this, a, his, hbox, dasyprocta, operatorname, Nearest to after: during, gland, when, was, iit, under, before, upanija, Nearest to were: are, was, have, had, being, be, been, gaulish, Nearest to over: kapoor, from, microbats, consulted, theosis, dancers, unmarried, in, Nearest to than: or, aegina, nanotube, firmness, limbs, while, undefined, circ, Nearest to to: ursus, can, would, will, agouti, busan, vma, callithrix, Nearest to had: has, have, was, were, is, by, never, dasyprocta, Average loss at step  92000 :  4.66340862286 Average loss at step  94000 :  4.73866039336 Average loss at step  96000 :  4.68984761286 Average loss at step  98000 :  4.59474902451 Average loss at step  100000 :  4.69168894279 Nearest to can: may, could, will, would, must, should, might, cannot, Nearest to at: in, on, birkenau, during, cebus, microcebus, agouti, busan, Nearest to in: during, at, from, on, under, within, ursus, agouti, Nearest to its: their, his, the, her, clinker, them, aquarius, pierrot, Nearest to into: from, through, under, busan, within, in, speedup, birkenau, Nearest to zero: five, eight, seven, nine, four, six, dasyprocta, operatorname, Nearest to war: influencing, soundly, emigrant, leaky, objection, studded, starfighter, calypso, Nearest to often: usually, also, there, generally, still, sometimes, widely, ursus, Nearest to so: iit, compromising, abet, neutral, por, sometimes, artifacts, however, Nearest to the: their, a, its, dasyprocta, this, operatorname, his, abet, Nearest to after: during, before, when, gland, in, iit, was, under, Nearest to were: are, was, have, had, be, being, is, gaulish, Nearest to over: kapoor, microbats, consulted, unmarried, theosis, dancers, from, during, Nearest to than: or, aegina, nanotube, circ, firmness, but, limbs, agouti, Nearest to to: ursus, would, agouti, callithrix, busan, can, recitative, vma, Nearest to had: has, have, was, were, never, by, dasyprocta, kapoor,

